{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.state = self.init_state()\n",
    "        self.step_count = 0\n",
    "\n",
    "    def init_state(self):\n",
    "        xs = random.sample(range(0, 7), 5)\n",
    "        ys = random.sample(range(0, 7), 5)\n",
    "        piece1 = (xs[0], ys[0])\n",
    "        playerpos = (xs[4], ys[4])\n",
    "        positions = list(np.array([playerpos, piece1]).flatten())\n",
    "        return positions\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = self.init_state()\n",
    "        self.step_count = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.step_count += 1\n",
    "        if action == 0:\n",
    "            self.state[1] += 1\n",
    "        elif action == 1:\n",
    "            self.state[0] += 1\n",
    "        elif action == 2:\n",
    "            self.state[1] -= 1\n",
    "        elif action == 3:\n",
    "            self.state[0] -= 1\n",
    "        \n",
    "        if self.step_count >= 25:\n",
    "            self.reset()\n",
    "            reward = int(rewarder(tf.expand_dims(self.state, 0), training=False)[0])\n",
    "            playing = False\n",
    "            return reward, playing\n",
    "        if (self.state[0] == self.state[2] and self.state[1] == self.state[3]):\n",
    "            playing = False\n",
    "            reward = int(rewarder(tf.expand_dims(self.state, 0), training=False)[0])\n",
    "            self.reset()\n",
    "            return reward, playing\n",
    "        \n",
    "        playing = True\n",
    "        reward = int(rewarder(tf.expand_dims(self.state, 0), training=False)[0])\n",
    "        return reward, playing\n",
    "    \n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self, num_actions, num_hidden_units):\n",
    "        super().__init__()\n",
    "        self.shared_1 = layers.Dense(num_hidden_units, activation='relu')\n",
    "        self.actor = layers.Dense(num_actions)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.shared_1(inputs)\n",
    "        return self.actor(x)\n",
    "    \n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self, num_hidden_units):\n",
    "        super().__init__()\n",
    "        self.shared_1 = layers.Dense(num_hidden_units, activation='relu')\n",
    "        self.reward = layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.shared_1(inputs)\n",
    "        return self.reward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_g(rewards, gamma):\n",
    "    ez_discount = np.array([gamma**i for i in range(len(rewards))])\n",
    "    gs = []\n",
    "    rewards = np.array(rewards)\n",
    "    for ts in range(len(rewards)):\n",
    "        to_end_reward = rewards[ts:]\n",
    "        eq_len_discount = ez_discount[:len(to_end_reward)]\n",
    "        g = np.multiply(to_end_reward, eq_len_discount).sum()\n",
    "        gs.append(g)\n",
    "    return gs\n",
    "\n",
    "def step_episode(S, model):\n",
    "    S.reset()\n",
    "    action_probs_list = []\n",
    "    rewards = []\n",
    "    states = []\n",
    "    actions = []\n",
    "    playing = True\n",
    "    while playing:\n",
    "        obs = tf.expand_dims(S.state, 0)\n",
    "        action_logits = model(obs)\n",
    "        selected_action_idx = tf.random.categorical(action_logits, 1)[0, 0]\n",
    "        states.append(obs)\n",
    "        actions.append(selected_action_idx)\n",
    "        reward, playing = S.step(selected_action_idx)\n",
    "        action_probs = tf.nn.softmax(action_logits)\n",
    "        probability_of_selected_action = action_probs[0, selected_action_idx]\n",
    "        action_probs_list.append(probability_of_selected_action)\n",
    "        rewards.append(reward)\n",
    "    return action_probs_list, rewards, states, actions\n",
    "\n",
    "def actor_loss(action_probs, rewards, states):\n",
    "    g = calc_g(rewards, 0.99)\n",
    "    action_probs = tf.convert_to_tensor(action_probs, dtype=tf.float32)\n",
    "    loss = -tf.math.reduce_sum(action_probs * g)\n",
    "    return loss\n",
    "\n",
    "def decode_action(action):\n",
    "    if action == 0:\n",
    "        return \"up\"\n",
    "    elif action == 1:\n",
    "        return \"right\"\n",
    "    elif action == 2:\n",
    "        return \"down\"\n",
    "    elif action == 3:\n",
    "        return \"left\"\n",
    "\n",
    "def compare(transition_ids, states, actions):\n",
    "    d1xs = [states[transition_ids[0]][0][0], states[transition_ids[0]][0][2]]\n",
    "    d1ys = [states[transition_ids[0]][0][1], states[transition_ids[0]][0][3]]\n",
    "    d2xs = [states[transition_ids[1]][0][0], states[transition_ids[1]][0][2]]\n",
    "    d2ys = [states[transition_ids[1]][0][1], states[transition_ids[1]][0][3]]\n",
    "\n",
    "    _, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    colors = ['b', 'r']\n",
    "    markers = ['o', 'X']\n",
    "    for i in range(2):\n",
    "        ax[0].scatter(d1xs[i], d1ys[i], c=colors[i], marker=markers[i])\n",
    "        ax[1].scatter(d2xs[i], d2ys[i], c=colors[i], marker=markers[i])\n",
    "    ax[0].set_title(str(decode_action(actions[transition_ids[0]].numpy())))\n",
    "    ax[1].set_title(str(decode_action(actions[transition_ids[1]].numpy())))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def preference_update(states, actions, rewarder, optimizer):\n",
    "    transition_ids = random.sample(range(len(states)-2), 2)\n",
    "    compare(transition_ids, states, actions)\n",
    "    pref = input(\"Select the better transition || q:left, d:right, s:same\")\n",
    "    if pref == \"q\":\n",
    "        dist = [1, 0]\n",
    "    elif pref == \"d\":\n",
    "        dist = [0, 1]\n",
    "    elif pref == \"s\":\n",
    "        dist = [1, 1]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        reward1 = rewarder(states[transition_ids[0] + 1])\n",
    "        reward2 = rewarder(states[transition_ids[1] + 1])\n",
    "        p1 = tf.nn.softmax(reward1)\n",
    "        p2 = tf.nn.softmax(reward2)\n",
    "        loss = -p1 * dist[0] - p2 * dist[1]\n",
    "    grads = tape.gradient(loss, rewarder.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, rewarder.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Actor(num_actions=4, num_hidden_units=128)\n",
    "rewarder = Critic(num_hidden_units=128)\n",
    "S = GridWorld()\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'dist' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, agent\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m      8\u001b[0m average_len\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(rewards))\n\u001b[1;32m----> 9\u001b[0m \u001b[43mpreference_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewarder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Length: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(episode, \u001b[38;5;28mlen\u001b[39m(rewards)))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Length: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(statistics\u001b[38;5;241m.\u001b[39mmean(average_len[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m:])))\n",
      "Cell \u001b[1;32mIn[49], line 84\u001b[0m, in \u001b[0;36mpreference_update\u001b[1;34m(states, actions, rewarder, optimizer)\u001b[0m\n\u001b[0;32m     82\u001b[0m     p1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(reward1)\n\u001b[0;32m     83\u001b[0m     p2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(reward2)\n\u001b[1;32m---> 84\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mp1 \u001b[38;5;241m*\u001b[39m \u001b[43mdist\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m p2 \u001b[38;5;241m*\u001b[39m dist[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     85\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, rewarder\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, rewarder\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'dist' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "average_len = []\n",
    "for episode in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        action_probs, rewards, states, actions = step_episode(S, agent)\n",
    "        loss = actor_loss(action_probs, rewards, states)\n",
    "    grads = tape.gradient(loss, agent.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, agent.trainable_variables))\n",
    "    average_len.append(len(rewards))\n",
    "    preference_update(states, actions, rewarder, optimizer)\n",
    "\n",
    "    print(\"Episode: {}, Length: {}\".format(episode, len(rewards)))\n",
    "    print(\"Average Length: {}\".format(statistics.mean(average_len[-100:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_simple_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
